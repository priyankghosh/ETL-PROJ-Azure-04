# Real-Time Patient Flow Analytics on Azure

![Azure](https://img.shields.io/badge/Azure-Cloud-blue?logo=microsoft-azure&style=flat-square)
![PySpark](https://img.shields.io/badge/PySpark-Big%20Data-orange?logo=apache-spark&style=flat-square)
![Azure Data Factory](https://img.shields.io/badge/Azure-Data%20Factory-blue?logo=microsoft-azure&style=flat-square)
![Azure Synapse](https://img.shields.io/badge/Azure-Synapse%20Analytics-blue?logo=microsoft-azure&style=flat-square)
![Python](https://img.shields.io/badge/Python-3.9+-yellow?logo=python&style=flat-square)
![Databricks](https://img.shields.io/badge/Databricks-PySpark-red?logo=databricks&style=flat-square)
![PowerBI](https://img.shields.io/badge/Power%20BI-Dashboard-orange?logo=power-bi&style=flat-square)
![Git](https://img.shields.io/badge/Git-CI%2FCD-green?logo=git&style=flat-square)

---

## ğŸ“‘ Table of Contents
- [ğŸ“Œ Project Overview](#-project-overview)
- [ğŸ¯ Objectives](#-objectives)
- [ğŸ“‚ Project Structure](#-project-structure)
- [ğŸ› ï¸ Tools & Technologies](#ï¸-tools--technologies)
- [ğŸ“ Data Architecture](#-data-architecture)
- [â­ Star Schema Design](#-star-schema-design)
- [âš™ï¸ Step-by-Step Implementation](#ï¸-step-by-step-implementation)
  - [1. Event Hub Setup](#1-event-hub-setup)
  - [2. Data Simulation](#2-data-simulation)
  - [3. Storage Setup](#3-storage-setup)
  - [4. Databricks Processing](#4-databricks-processing)
  - [5. Synapse SQL Pool](#5-synapse-sql-pool)
  - [6. Version Control](#6-version-control)
- [ğŸ“Š Data Analytics](#-data-analytics)
- [âœ… Key Outcomes](#-key-outcomes)
- [ğŸ“œ License](#-license)

---

## ğŸ“Œ Project Overview
This project demonstrates a **real-time data engineering pipeline** for healthcare, designed to analyze **patient flow across hospital departments** using Azure cloud services.  
The pipeline ingests streaming data, processes it in **Databricks (PySpark)**, and stores it in **Azure Synapse SQL Pool** for analytics and finally visualisation in Power BI and design an interactive dashboard for hospital KPIs.

## Pipeline

<img width="4719" height="2432" alt="Architecture" src="https://github.com/user-attachments/assets/cb1a1775-ab64-45d7-b45b-50ba97660e1d" />

## All resources in resource grp
![rg-snap](./snaps/rg-snap.PNG)
---

## ğŸ¯ Objectives
- Collect real-time patient data via **Azure Event Hub**.
- Process and cleanse data using **Databricks** (Bronze â†’ Silver â†’ Gold layers).
- Implement a **star schema** in **Synapse SQL Pool** for efficient querying.
- Enable **Version Control** with Git.

---

## ğŸ“‚ Project Structure
```
ETL-PROJ-AZURE-DATABRICKS_04/
    â”œâ”€â”€ client_requirements/
    â”‚   â””â”€â”€ client_requirements_de.pdf       # Demo Client Requirement
    â”œâ”€â”€ databricks-notebooks/
    â”‚   â”œâ”€â”€ 01-bronzerawdata.ipynb           # Data Ingestion & Raw Layer (Bronze) Notebook
    â”‚   â”œâ”€â”€ 02-silver-cleandata.ipynb        # Data Cleaning & Conformed Layer (Silver) Notebook
    â”‚   â””â”€â”€ 03-gold-transform.ipynb          # Data Transformation & Aggregate Layer (Gold) Notebook
    â”œâ”€â”€ powerbi/
    â”‚   â””â”€â”€ Healthcare_Visualisation-Dashboard.pbix # Power BI Dashboard file
    â”œâ”€â”€ simulator/
    â”‚   â””â”€â”€ patient_flow_generator.py        # Python script for generating simulated data
    â”œâ”€â”€ snaps/                               # Directory for screenshots or reference images
    â”‚   â””â”€â”€ rg-snap.PNG                      # Snapshot of a Resource Group or similar
    â”œâ”€â”€ sqlpool-queries/                     # Dedicated SQL scripts for the data warehouse (Synapse SQL Pool)
    â”‚   â”œâ”€â”€ Final Business Views.sql         # Final SQL views for reporting/consumption
    â”‚   â”œâ”€â”€ Pre-Requisites.sql               # SQL scripts for setting up necessary objects
    â”‚   â””â”€â”€ Tables.sql                       # SQL scripts for table creation/DDL
    â”œâ”€â”€ .gitignore                           # Git ignore fileinformation/notes
    â””â”€â”€ README.md                            # Main project documentation (where this structure goes)

```

---

## ğŸ› ï¸ Tools & Technologies
- **Azure Event Hub** â€“ Real-time data ingestion
- **Azure Databricks** â€“ PySpark-based ETL processing
- **Azure Data Lake Storage** â€“ Staging raw and curated data
- **Azure Synapse SQL Pool** â€“ Data warehouse for analytics
- **Power BI** â€“ Dashboarding (future step)
- **Python 3.9+** â€“ Core programming
- **Git** â€“ Version control

---

## ğŸ“ Data Architecture
The pipeline follows a **multi-layered architecture**:
- **Bronze Layer**: Raw JSON data from Event Hub stored in ADLS.
- **Silver Layer**: Cleaned and structured data (validated types, null handling).
- **Gold Layer**: Aggregated and transformed data ready for BI consumption.

---

## â­ Star Schema Design
The **Gold layer** data in Synapse follows a **star schema** for optimized analytics:
- **Fact Table**: `FactPatientFlow` (patient visits, timestamps, wait times, discharge)
- **Dimension Tables**:
  - `DimDepartment` â€“ Department details
  - `DimPatient` â€“ Patient demographic info
  - `DimTime` â€“ Date and time dimension

---

## âš™ï¸ Step-by-Step Implementation

### **1. Event Hub Setup**
- Created **Event Hub namespace** and **patient-flow hub**.
- Configured **consumer groups** for Databricks streaming.

---

### **2. Data Simulation**
- Developed **Python script** `patient_flow_generator.py` to stream fake patient data (departments, wait time, discharge status) to Event Hub.
- [Producer Code](simulator/patient_flow_generator.py)

---

### **3. Storage Setup**
- Configured **Azure Data Lake Storage (ADLS Gen2)**.
- Created containers for **bronze**, **silver**, and **gold** layers.

---

### **4. Databricks Processing**
- [**Notebook 1**](databricks-notebooks/01_bronze_rawdata.py): Reads Event Hub stream into Bronze.
- [**Notebook 2**](databricks-notebooks/02_silver_cleandata.py): Cleans and validates schema.
- [**Notebook 3** ](databricks-notebooks/03_gold_transform.py): Aggregates and prepares star schema tables.

---

### **5. Synapse SQL Pool**
- Created **dedicated SQL Pool**.
- Executed schema and fact/dimension creation queries from

---

### **6. Version Control**
- Version control with **Git**

<br />
<br />

## ğŸ“Š Data Analytics

Once the **data pipeline** was established and a **Star Schema** implemented in Synapse SQL Pool, the next step was to build an **interactive dashboard in Power BI**.  

### **ğŸ”— Synapse â†’ Power BI Connection**
- Connected **Azure Synapse SQL Pool** to Power BI using a direct SQL connection.  
- Imported **FactPatientFlow** and **Dimension tables**.  
- Established relationships for **Star Schema-based reporting**.  

<br />

## âœ… Key Outcomes
- **End-to-End Pipeline:** From **real-time ingestion â†’ transformation â†’ warehouse â†’ analytics**.  
- **Scalable Architecture:** Easily adaptable for different hospital datasets.  
- **Business Insights:** Hospital admins can monitor **bed usage, patient flow, and department efficiency** in real time.  
- **Portfolio Value:** Demonstrates both **Data Engineering** and **Analytics skills** in one project.  

